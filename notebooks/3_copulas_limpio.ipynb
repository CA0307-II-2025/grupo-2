{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e9197a",
   "metadata": {},
   "source": [
    "## Paquetes Necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621a62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, kstest, kendalltau, t as tdist\n",
    "\n",
    "from statsmodels.distributions.copula.api import (\n",
    "    GumbelCopula,\n",
    "    StudentTCopula,\n",
    ")\n",
    "\n",
    "df = pd.read_csv('../data/clean/datos_limpios_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962379b6",
   "metadata": {},
   "source": [
    "## Cargar modelos marginales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae64ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_cola(name: str, carpeta: str) -> Dict:\n",
    "    pattern = os.path.join(carpeta, f\"{name}_tail_*.csv\")\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No se encontró tail para {name} en {carpeta}\")\n",
    "\n",
    "    ruta = files[0]\n",
    "    dfp = pd.read_csv(ruta)\n",
    "\n",
    "    if dfp.empty:\n",
    "        raise ValueError(f\"CSV de tail vacío: {ruta}\")\n",
    "\n",
    "    model = str(dfp.loc[0, \"model_name\"]).strip()\n",
    "    u = float(dfp.loc[0, \"u_opt\"])\n",
    "    p_u = float(dfp.loc[0, \"p_u\"])\n",
    "\n",
    "    param_cols = [c for c in dfp.columns if \"param\" in c.lower()]\n",
    "    param_cols = sorted(param_cols,\n",
    "                        key=lambda s: int(\"\".join(filter(str.isdigit, s)) or 0))\n",
    "    params = tuple(float(dfp.loc[0, c]) for c in param_cols)\n",
    "\n",
    "    return {\"model\": model, \"u\": u, \"p_u\": p_u, \"params\": params}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647be703",
   "metadata": {},
   "source": [
    "## Obtener CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6512a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_exc_tail(y: float, model: str, params: Tuple[float, ...]) -> float:\n",
    "\n",
    "    if y <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    m = model.lower()\n",
    "\n",
    "    if m == \"gpd\":\n",
    "        sigma, xi = params\n",
    "        if abs(xi) < 1e-12:\n",
    "            return 1.0 - np.exp(-y / sigma)\n",
    "        base = 1.0 + xi * y / sigma\n",
    "        if base <= 0:\n",
    "            return 1.0\n",
    "        return 1.0 - base ** (-1.0 / xi)\n",
    "\n",
    "    if m == \"pareto\":\n",
    "        xm, k = params\n",
    "        return 1.0 - (xm / (xm + y)) ** k\n",
    "\n",
    "    if m == \"burr\":\n",
    "        c, k, lam = params\n",
    "        return 1.0 - (1.0 + (y / lam) ** c) ** (-k)\n",
    "\n",
    "    if m.startswith(\"ln\") or m.startswith(\"lognormal\"):\n",
    "        mu, sig = params\n",
    "        return float(norm.cdf((np.log(y) - mu) / sig))\n",
    "\n",
    "    raise ValueError(f\"Modelo de cola no implementado en F_exc_tail: {model}\")\n",
    "\n",
    "\n",
    "def F_hybrid(x: float,\n",
    "             body_sample: np.ndarray,\n",
    "             tail: Dict,\n",
    "             a: float = 1.0,\n",
    "             b: float = 2.0) -> float:\n",
    "\n",
    "    u = tail[\"u\"]\n",
    "    p_u = tail[\"p_u\"]\n",
    "\n",
    "    if x <= u:\n",
    "        sample = np.asarray(body_sample)\n",
    "        sample = sample[~np.isnan(sample)]\n",
    "        if sample.size == 0:\n",
    "            return np.nan\n",
    "        s = np.sort(sample)\n",
    "        r = np.searchsorted(s, x, side=\"right\")\n",
    "        return (r + a) / (len(s) + b)\n",
    "\n",
    "    y = x - u\n",
    "    Fexc = F_exc_tail(y, tail[\"model\"], tail[\"params\"])\n",
    "    return 1.0 - p_u * (1.0 - Fexc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e7d03",
   "metadata": {},
   "source": [
    "## Pasar a Unif con prueba KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36acb87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test_uniform(U: np.ndarray) -> Tuple[float, float]:\n",
    "\n",
    "    stat, pval = kstest(U, \"uniform\")\n",
    "    return float(stat), float(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74108f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_variable(series: pd.Series,\n",
    "               name: str,\n",
    "               carpeta_tail: str,\n",
    "               clip_eps: float = 1e-6) -> Tuple[np.ndarray, np.ndarray, Dict, float, float]:\n",
    "\n",
    "    tail = cargar_cola(name, carpeta_tail)\n",
    "\n",
    "    vals = series.to_numpy(dtype=float)\n",
    "    body_sample = vals[vals <= tail[\"u\"]]\n",
    "\n",
    "    U = np.array(\n",
    "        [F_hybrid(float(x), body_sample, tail) for x in vals],\n",
    "        dtype=float\n",
    "    )\n",
    "    U = np.clip(U, clip_eps, 1.0 - clip_eps)\n",
    "\n",
    "    ks_stat, ks_p = ks_test_uniform(U)\n",
    "    return U, body_sample, tail, ks_stat, ks_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ab358",
   "metadata": {},
   "source": [
    "## Ajuste de Cópulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f60644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_copulas(U1: np.ndarray,\n",
    "                U2: np.ndarray) -> Dict:\n",
    "\n",
    "    U1 = np.asarray(U1, float)\n",
    "    U2 = np.asarray(U2, float)\n",
    "    mask = np.isfinite(U1) & np.isfinite(U2)\n",
    "    data = np.column_stack([U1[mask], U2[mask]])\n",
    "\n",
    "    if data.shape[0] < 5:\n",
    "        raise ValueError(\"Muy pocos datos para ajustar cópulas\")\n",
    "\n",
    "    # ============================\n",
    "    # 1) Kendall tau (una sola vez)\n",
    "    # ============================\n",
    "    tau, _ = kendalltau(data[:, 0], data[:, 1])\n",
    "    if not np.isfinite(tau):\n",
    "        tau = 0.0\n",
    "\n",
    "    # ============================\n",
    "    # 2) Gumbel\n",
    "    # ============================\n",
    "    tau_g = np.clip(tau, 1e-6, 0.999)\n",
    "    theta = 1.0 / (1.0 - tau_g)  # θ de Gumbel\n",
    "    gcop = GumbelCopula(theta=theta)\n",
    "\n",
    "    ll_g = float(np.sum(gcop.logpdf(data)))\n",
    "    aic_g = -2.0 * ll_g + 2.0 * 1  # k=1\n",
    "\n",
    "    # ============================\n",
    "    # 3) t-Student\n",
    "    # ============================\n",
    "    tcop = StudentTCopula()\n",
    "\n",
    "    # Estimar parámetros internos (incluye correlación y nu)\n",
    "    params = tcop.fit(data)   # <-- ESTA ES LA CLAVE\n",
    "\n",
    "    # loglik\n",
    "    ll_t = float(np.sum(tcop.logpdf(data)))  # sin argumentos nombrados\n",
    "\n",
    "    # parámetros: correlación y nu están dentro de params\n",
    "    rho_t = params[\"corr\"][0, 1]\n",
    "    nu_t  = params[\"df\"]\n",
    "\n",
    "    R = params[\"corr\"]\n",
    "    nu = float(params[\"df\"])\n",
    "\n",
    "    aic_t = -2.0 * ll_t + 2.0 * 2  # parámetros = rho + nu\n",
    "\n",
    "\n",
    "    # ============================\n",
    "    # 4) Modelo ganador\n",
    "    # ============================\n",
    "    winner = \"t-student\" if aic_t < aic_g else \"gumbel\"\n",
    "\n",
    "    return {\n",
    "        \"tau\": float(tau),\n",
    "        \"gumbel\": {\n",
    "            \"theta\": float(theta),\n",
    "            \"ll\": ll_g,\n",
    "            \"aic\": aic_g\n",
    "        },\n",
    "        \"t\": {\n",
    "            \"R\": R,\n",
    "            \"nu\": float(nu),\n",
    "            \"ll\": ll_t,\n",
    "            \"aic\": aic_t\n",
    "        },\n",
    "        \"winner\": winner\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67f6ef",
   "metadata": {},
   "source": [
    "## Simular la Cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec595afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_copula(fit: Dict,\n",
    "                    n_sims: int = 50_000,\n",
    "                    random_state: Optional[int] = None) -> np.ndarray:\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    if fit[\"winner\"] == \"gumbel\":\n",
    "        theta = fit[\"gumbel\"][\"theta\"]\n",
    "        cop = GumbelCopula(theta=theta)\n",
    "        if hasattr(cop, \"random\"):\n",
    "            U = cop.random(n_sims, random_state=random_state)\n",
    "        else:\n",
    "            U = cop.rvs(n_sims, random_state=random_state)\n",
    "        U = np.asarray(U, float)\n",
    "\n",
    "    else:\n",
    "        R = np.asarray(fit[\"t\"][\"R\"], float)\n",
    "        nu = float(fit[\"t\"][\"nu\"])\n",
    "        k = R.shape[0]\n",
    "\n",
    "        L = np.linalg.cholesky(R + 1e-12 * np.eye(k))\n",
    "\n",
    "        g = rng.standard_normal(size=(n_sims, k))\n",
    "        z = g @ L.T\n",
    "\n",
    "        w = rng.chisquare(df=nu, size=n_sims) / nu\n",
    "        t_samples = z / np.sqrt(w[:, None])\n",
    "\n",
    "        U = tdist.cdf(t_samples, df=nu)\n",
    "\n",
    "    return np.clip(U, 1e-12, 1.0 - 1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a397f31",
   "metadata": {},
   "source": [
    "## Cuantil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4091bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_hybrid(alpha: float,\n",
    "             body_sample: np.ndarray,\n",
    "             tail: Dict) -> float:\n",
    "\n",
    "    alpha = float(np.clip(alpha, 1e-12, 1.0 - 1e-12))\n",
    "    u = tail[\"u\"]\n",
    "    p_u = tail[\"p_u\"]\n",
    "\n",
    "    sample = np.asarray(body_sample)\n",
    "    sample = sample[~np.isnan(sample)]\n",
    "\n",
    "    if alpha <= (1.0 - p_u) or sample.size == 0:\n",
    "        return float(np.quantile(sample, alpha))\n",
    "\n",
    "    alpha_exc = (alpha - (1.0 - p_u)) / p_u\n",
    "    alpha_exc = float(np.clip(alpha_exc, 1e-12, 1.0 - 1e-12))\n",
    "\n",
    "    m = tail[\"model\"].lower()\n",
    "    params = tail[\"params\"]\n",
    "\n",
    "    if m == \"gpd\":\n",
    "        sigma, xi = params\n",
    "        if abs(xi) < 1e-12:\n",
    "            q_exc = -sigma * np.log1p(-alpha_exc)\n",
    "        else:\n",
    "            q_exc = (sigma / xi) * (np.power(1.0 - alpha_exc, -xi) - 1.0)\n",
    "\n",
    "    elif m == \"pareto\":\n",
    "        xm, k = params\n",
    "        q_exc = xm * (np.power(1.0 - alpha_exc, -1.0 / k) - 1.0)\n",
    "\n",
    "    elif m == \"burr\":\n",
    "        c, k, lam = params\n",
    "        inner = np.power(1.0 - alpha_exc, -1.0 / k) - 1.0\n",
    "        inner = max(inner, 1e-18)\n",
    "        q_exc = lam * (inner ** (1.0 / c))\n",
    "\n",
    "    elif m.startswith(\"ln\") or m.startswith(\"lognormal\"):\n",
    "        mu, sig = params\n",
    "        z = norm.ppf(alpha_exc)\n",
    "        q_exc = np.exp(mu + sig * z)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo no implementado en Q_hybrid: {tail['model']}\")\n",
    "\n",
    "    return float(u + q_exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72cecb",
   "metadata": {},
   "source": [
    "## VaR y CVaR para parejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc12a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_joint_losses(U_sim: np.ndarray,\n",
    "                          body1: np.ndarray,\n",
    "                          tail1: Dict,\n",
    "                          body2: np.ndarray,\n",
    "                          tail2: Dict) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Recibe:\n",
    "        U_sim: matriz (N x 2) de uniformes conjuntas (salida de simulate_copula)\n",
    "        body1, tail1: muestra de cuerpo + cola para la variable 1\n",
    "        body2, tail2: idem para la variable 2\n",
    "\n",
    "    Devuelve:\n",
    "        X1, X2, S = X1 + X2\n",
    "    \"\"\"\n",
    "    U1 = U_sim[:, 0]\n",
    "    U2 = U_sim[:, 1]\n",
    "\n",
    "    X1 = np.array([Q_hybrid(float(a), body1, tail1) for a in U1], dtype=float)\n",
    "    X2 = np.array([Q_hybrid(float(a), body2, tail2) for a in U2], dtype=float)\n",
    "    S = X1 + X2\n",
    "    return X1, X2, S\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. VAR Y CVAR DE UNA SERIE\n",
    "# ============================================================\n",
    "\n",
    "def var_cvar(S: np.ndarray, alpha: float) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calcula VaR y CVaR (TVaR) empíricos para una muestra S.\n",
    "\n",
    "    VaR = cuantil alpha\n",
    "    CVaR = media condicional S > VaR\n",
    "    \"\"\"\n",
    "    S = np.asarray(S, float)\n",
    "    S = S[np.isfinite(S)]\n",
    "\n",
    "    if S.size == 0:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    q = float(np.quantile(S, alpha))\n",
    "    tail = S[S > q]\n",
    "    cvar = float(tail.mean()) if tail.size > 0 else q\n",
    "    return q, cvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a24d6c",
   "metadata": {},
   "source": [
    "## Pipe completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f7d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependencia_y_riesgo(df: pd.DataFrame,\n",
    "                         col1: str,\n",
    "                         val1: str,\n",
    "                         carpeta1: str,\n",
    "                         col2: str,\n",
    "                         val2: str,\n",
    "                         carpeta2: str,\n",
    "                         n_sims: int = 50_000,\n",
    "                         alphas: Tuple[float, ...] = (0.95, 0.99),\n",
    "                         random_state: Optional[int] = None) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Pipeline completo para una pareja (val1 de col1) vs (val2 de col2):\n",
    "\n",
    "    1) filtra df por col1 == val1 y col2 == val2\n",
    "    2) obtiene U1, U2 via F_hybrid + cola EVT\n",
    "    3) KS test de uniformidad para U1 y U2\n",
    "    4) ajusta cópulas Gumbel y t-Student y elige la mejor\n",
    "    5) simula U_sim ~ copula ganadora\n",
    "    6) aplica Q_hybrid para obtener X1, X2 y S = X1+X2\n",
    "    7) calcula VaR y CVaR para cada alpha en alphas\n",
    "\n",
    "    Devuelve un diccionario con resultados o None si no hay datos suficientes.\n",
    "    \"\"\"\n",
    "    df_pair = df[(df[col1] == val1) & (df[col2] == val2)].copy()\n",
    "    if df_pair.shape[0] < 20:\n",
    "        # muy pocos datos\n",
    "        return None\n",
    "\n",
    "    # Marginal 1\n",
    "    U1, body1, tail1, ks1_stat, ks1_p = U_variable(\n",
    "        df_pair[\"total\"], name=str(val1), carpeta_tail=carpeta1\n",
    "    )\n",
    "\n",
    "    # Marginal 2\n",
    "    U2, body2, tail2, ks2_stat, ks2_p = U_variable(\n",
    "        df_pair[\"total\"], name=str(val2), carpeta_tail=carpeta2\n",
    "    )\n",
    "\n",
    "    # Ajuste de cópulas\n",
    "    fit = fit_copulas(U1, U2)\n",
    "\n",
    "    # Simulación conjunta en espacio U\n",
    "    U_sim = simulate_copula(fit, n_sims=n_sims, random_state=random_state)\n",
    "\n",
    "    # Simulación de pérdidas\n",
    "    X1, X2, S = simulate_joint_losses(U_sim, body1, tail1, body2, tail2)\n",
    "\n",
    "    res = {\n",
    "        \"col1\": col1,\n",
    "        \"val1\": val1,\n",
    "        \"col2\": col2,\n",
    "        \"val2\": val2,\n",
    "        \"n_obs\": int(df_pair.shape[0]),\n",
    "        \"ks1_stat\": ks1_stat,\n",
    "        \"ks1_p\": ks1_p,\n",
    "        \"ks2_stat\": ks2_stat,\n",
    "        \"ks2_p\": ks2_p,\n",
    "        \"tau\": fit[\"tau\"],\n",
    "        \"best_copula\": fit[\"winner\"],\n",
    "        \"gumbel_aic\": fit[\"gumbel\"][\"aic\"],\n",
    "        \"t_aic\": fit[\"t\"][\"aic\"],\n",
    "    }\n",
    "\n",
    "    for a in alphas:\n",
    "        VaR, CVaR_ = var_cvar(S, a)\n",
    "        res[f\"VaR({a})\"] = VaR\n",
    "        res[f\"CVaR({a})\"] = CVaR_\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf724917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def todas_dependencias(\n",
    "    df: pd.DataFrame,\n",
    "    provincias: List[str],\n",
    "    categorias: List[str],\n",
    "    sectores: List[str],\n",
    "    carpeta_prov: str = \"../res/provincia\",\n",
    "    carpeta_cat: str = \"../res/categoria\",\n",
    "    carpeta_sec: str = \"../res/sector\",\n",
    "    n_sims: int = 50_000,\n",
    "    alphas: Tuple[float, ...] = (0.95, 0.99),\n",
    "    random_state: Optional[int] = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ejecuta dependencia_y_riesgo para:\n",
    "\n",
    "        1) provincia - sector\n",
    "        2) provincia - categoria\n",
    "        3) categoria - sector\n",
    "\n",
    "    y devuelve un DataFrame con todos los resultados.\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "\n",
    "    # 1) provincia - sector\n",
    "    for p in provincias:\n",
    "        for s in sectores:\n",
    "            r = dependencia_y_riesgo(\n",
    "                df, \"provincia\", p, carpeta_prov,\n",
    "                \"sector\", s, carpeta_sec,\n",
    "                n_sims=n_sims, alphas=alphas, random_state=random_state\n",
    "            )\n",
    "            if r is not None:\n",
    "                r[\"tipo_par\"] = \"provincia-sector\"\n",
    "                resultados.append(r)\n",
    "\n",
    "    # 2) provincia - categoria\n",
    "    for p in provincias:\n",
    "        for c in categorias:\n",
    "            r = dependencia_y_riesgo(\n",
    "                df, \"provincia\", p, carpeta_prov,\n",
    "                \"categoria\", c, carpeta_cat,\n",
    "                n_sims=n_sims, alphas=alphas, random_state=random_state\n",
    "            )\n",
    "            if r is not None:\n",
    "                r[\"tipo_par\"] = \"provincia-categoria\"\n",
    "                resultados.append(r)\n",
    "\n",
    "    # 3) categoria - sector\n",
    "    for c in categorias:\n",
    "        for s in sectores:\n",
    "            r = dependencia_y_riesgo(\n",
    "                df, \"categoria\", c, carpeta_cat,\n",
    "                \"sector\", s, carpeta_sec,\n",
    "                n_sims=n_sims, alphas=alphas, random_state=random_state\n",
    "            )\n",
    "            if r is not None:\n",
    "                r[\"tipo_par\"] = \"categoria-sector\"\n",
    "                resultados.append(r)\n",
    "\n",
    "    if not resultados:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f889253",
   "metadata": {},
   "source": [
    "# Uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f691a286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\transforms.py:139: RuntimeWarning: overflow encountered in power\n",
      "  return np.power(-np.log(t), theta)\n",
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\transforms.py:145: RuntimeWarning: overflow encountered in power\n",
      "  return - theta * (-np.log(t))**(theta - 1) / t\n",
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\archimedean.py:187: RuntimeWarning: divide by zero encountered in log\n",
      "  logpdfv = np.sum(np.log(np.abs(phi_d1(u, *args))), axis)\n",
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\transforms.py:158: RuntimeWarning: overflow encountered in square\n",
      "  d2 = (phi**(2 / th) + (th - 1) * phi**(1 / th)) / (phi**2 * th**2)\n",
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\transforms.py:158: RuntimeWarning: overflow encountered in multiply\n",
      "  d2 = (phi**(2 / th) + (th - 1) * phi**(1 / th)) / (phi**2 * th**2)\n",
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\transforms.py:158: RuntimeWarning: divide by zero encountered in divide\n",
      "  d2 = (phi**(2 / th) + (th - 1) * phi**(1 / th)) / (phi**2 * th**2)\n",
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\transforms.py:158: RuntimeWarning: invalid value encountered in divide\n",
      "  d2 = (phi**(2 / th) + (th - 1) * phi**(1 / th)) / (phi**2 * th**2)\n",
      "c:\\Users\\andre\\anaconda3\\envs\\Proyectos\\Lib\\site-packages\\statsmodels\\distributions\\copula\\archimedean.py:188: RuntimeWarning: divide by zero encountered in log\n",
      "  logpdfv += np.log(np.abs(psi_d(psi, *args)))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StudentTCopula' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m categorias = \u001b[38;5;28msorted\u001b[39m(df[\u001b[33m\"\u001b[39m\u001b[33mcategoria\u001b[39m\u001b[33m\"\u001b[39m].dropna().unique())\n\u001b[32m      4\u001b[39m sectores   = \u001b[38;5;28msorted\u001b[39m(df[\u001b[33m\"\u001b[39m\u001b[33msector\u001b[39m\u001b[33m\"\u001b[39m].dropna().unique())\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m tabla = \u001b[43mtodas_dependencias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovincias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovincias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msectores\u001b[49m\u001b[43m=\u001b[49m\u001b[43msectores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcarpeta_prov\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../res/provincias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcarpeta_cat\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../res/categorias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcarpeta_sec\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../res/sectores\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_sims\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.99\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m123\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m tabla.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtodas_dependencias\u001b[39m\u001b[34m(df, provincias, categorias, sectores, carpeta_prov, carpeta_cat, carpeta_sec, n_sims, alphas, random_state)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m provincias:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sectores:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         r = \u001b[43mdependencia_y_riesgo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprovincia\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarpeta_prov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msector\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarpeta_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_sims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_sims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43malphas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     33\u001b[39m             r[\u001b[33m\"\u001b[39m\u001b[33mtipo_par\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mprovincia-sector\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mdependencia_y_riesgo\u001b[39m\u001b[34m(df, col1, val1, carpeta1, col2, val2, carpeta2, n_sims, alphas, random_state)\u001b[39m\n\u001b[32m     35\u001b[39m U2, body2, tail2, ks2_stat, ks2_p = U_variable(\n\u001b[32m     36\u001b[39m     df_pair[\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m], name=\u001b[38;5;28mstr\u001b[39m(val2), carpeta_tail=carpeta2\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Ajuste de cópulas\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m fit = \u001b[43mfit_copulas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Simulación conjunta en espacio U\u001b[39;00m\n\u001b[32m     43\u001b[39m U_sim = simulate_copula(fit, n_sims=n_sims, random_state=random_state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mfit_copulas\u001b[39m\u001b[34m(U1, U2)\u001b[39m\n\u001b[32m     32\u001b[39m tcop = StudentTCopula()\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Estimar parámetros internos (incluye correlación y nu)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m params = \u001b[43mtcop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m(data)   \u001b[38;5;66;03m# <-- ESTA ES LA CLAVE\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# loglik\u001b[39;00m\n\u001b[32m     38\u001b[39m ll_t = \u001b[38;5;28mfloat\u001b[39m(np.sum(tcop.logpdf(data)))  \u001b[38;5;66;03m# sin argumentos nombrados\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'StudentTCopula' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# Supongamos que df ya está cargado y limpio\n",
    "provincias = sorted(df[\"provincia\"].dropna().unique())\n",
    "categorias = sorted(df[\"categoria\"].dropna().unique())\n",
    "sectores   = sorted(df[\"sector\"].dropna().unique())\n",
    "\n",
    "tabla = todas_dependencias(\n",
    "    df,\n",
    "    provincias=provincias,\n",
    "    categorias=categorias,\n",
    "    sectores=sectores,\n",
    "    carpeta_prov=\"../res/provincias\",\n",
    "    carpeta_cat=\"../res/categorias\",\n",
    "    carpeta_sec=\"../res/sectores\",\n",
    "    n_sims=200_000,\n",
    "    alphas=(0.95, 0.99),\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "tabla.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proyectos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
